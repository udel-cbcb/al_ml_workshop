{"cells":[{"cell_type":"markdown","source":["#**Wine Types Analysis Using Deep Learning**\n","\n","We will now focus on our main objectives of building predictive models to predict the wine types (red or white wine) based on other features using Deep Learning. \n","\n","Adapted from Dipanjan Sarkar et al. 2018. [Practical Machine Learning with Python](https://link.springer.com/book/10.1007/978-1-4842-3207-1)."],"metadata":{"id":"aDjF76ImzxKN"}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"jeqbjUnXy2TX"},"outputs":[],"source":["# Import necessary dependencies\n","# We wil use matplotlib and seaborn for exploratory data analysis and visualizations\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from collections import Counter\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import LabelEncoder\n","\n","%matplotlib inline"]},{"cell_type":"markdown","source":["#Download Wine Quality Datasets"],"metadata":{"id":"saX_8Cah4fxQ"}},{"cell_type":"code","source":["!pip install wget\n","!python -m wget -o winequality-red.csv \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n","!python -m wget -o winequality-white.csv \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n","!python -m wget -o winequality.names \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality.names\""],"metadata":{"id":"Rq_CPonD4mg0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655162912283,"user_tz":240,"elapsed":15309,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"}},"outputId":"ae01c94c-fb78-4475-c84d-fb7a3088fab1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wget\n","  Downloading wget-3.2.zip (10 kB)\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=f5820b53db18550500fcf10b35a13fa2e1ca2ba3ece45acca431676c74ca13ee\n","  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n","Successfully built wget\n","Installing collected packages: wget\n","Successfully installed wget-3.2\n","\n","Saved under winequality-red.csv\n","\n","Saved under winequality-white.csv\n","\n","Saved under winequality.names\n"]}]},{"cell_type":"markdown","metadata":{"id":"pbb4BZzYy2TY"},"source":["# Load and merge datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5u2b3VtPy2TZ"},"outputs":[],"source":["white_wine = pd.read_csv('winequality-white.csv', sep=';')\n","red_wine = pd.read_csv('winequality-red.csv', sep=';')\n","\n","# store wine type as an attribute\n","red_wine['wine_type'] = 'red'   \n","white_wine['wine_type'] = 'white'\n","# bucket wine quality scores into qualitative quality labels\n","# Wine quality scores of 3, 4, and 5 are mapped to low quality,\n","# 6 and 7 are mapped to medium quality, 8 and 9 are mapped to high quality \n","# wines under the quality_label attribute. \n","red_wine['quality_label'] = red_wine['quality'].apply(lambda value: 'low' \n","                                                          if value <= 5 else 'medium' \n","                                                              if value <= 7 else 'high')\n","red_wine['quality_label'] = pd.Categorical(red_wine['quality_label'], \n","                                           categories=['low', 'medium', 'high'])\n","white_wine['quality_label'] = white_wine['quality'].apply(lambda value: 'low' \n","                                                              if value <= 5 else 'medium' \n","                                                                  if value <= 7 else 'high')\n","white_wine['quality_label'] = pd.Categorical(white_wine['quality_label'], \n","                                             categories=['low', 'medium', 'high'])\n","\n","# merge red and white wine datasets\n","wines = pd.concat([red_wine, white_wine])\n","# re-shuffle records just to randomize data points\n","wines = wines.sample(frac=1, random_state=42).reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{"id":"6NisWsPzy2Ta"},"source":["# Understand dataset features and values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NNVKwRe6y2Ta"},"outputs":[],"source":["print(white_wine.shape, red_wine.shape)\n","print(wines.info())"]},{"cell_type":"markdown","source":["We have 4898 white wine data points and 1599 red wine data points. The\n","merged dataset contains a total of 6497 data points and we also get an idea of numeric and categorical\n","attributes."],"metadata":{"id":"K3thHV0SEuIf"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"23TI5msyy2Tb"},"outputs":[],"source":["# Let’s take a peek at our dataset to see some sample data points.\n","wines.head()"]},{"cell_type":"markdown","source":["#Utilty functions for model evaluation"],"metadata":{"id":"HDPzEHdm26N7"}},{"cell_type":"code","source":["from sklearn import metrics\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.base import clone\n","from sklearn.preprocessing import label_binarize\n","from scipy import interp\n","from sklearn.metrics import roc_curve, auc \n","\n","def get_metrics(true_labels, predicted_labels):\n","    \n","    print('Accuracy:', np.round(\n","                        metrics.accuracy_score(true_labels, \n","                                               predicted_labels),\n","                        4))\n","    print('Precision:', np.round(\n","                        metrics.precision_score(true_labels, \n","                                               predicted_labels,\n","                                               average='weighted'),\n","                        4))\n","    print('Recall:', np.round(\n","                        metrics.recall_score(true_labels, \n","                                               predicted_labels,\n","                                               average='weighted'),\n","                        4))\n","    print('F1 Score:', np.round(\n","                        metrics.f1_score(true_labels, \n","                                               predicted_labels,\n","                                               average='weighted'),\n","                        4))\n","def display_classification_report(true_labels, predicted_labels, classes=[1,0]):\n","\n","    report = metrics.classification_report(y_true=true_labels, \n","                                           y_pred=predicted_labels, \n","                                           labels=classes) \n","    print(report)\n","    \n","def display_confusion_matrix(true_labels, predicted_labels, classes=[1,0]):\n","    \n","    total_classes = len(classes)\n","    level_labels = [total_classes*[0], list(range(total_classes))]\n","    cm = metrics.confusion_matrix(y_true=true_labels, y_pred=predicted_labels, \n","                                  labels=classes)\n","    cm_frame = pd.DataFrame(data=cm, \n","                            columns=pd.MultiIndex(levels=[['Predicted:'], classes], \n","                                                  codes=level_labels), \n","                            index=pd.MultiIndex(levels=[['Actual:'], classes], \n","                                                codes=level_labels)) \n","    print(cm_frame) \n","\n","def display_model_performance_metrics(true_labels, predicted_labels, classes=[1,0]):\n","    print('Model Performance metrics:')\n","    print('-'*30)\n","    get_metrics(true_labels=true_labels, predicted_labels=predicted_labels)\n","    print('\\nModel Classification report:')\n","    print('-'*30)\n","    display_classification_report(true_labels=true_labels, predicted_labels=predicted_labels, \n","                                  classes=classes)\n","    print('\\nPrediction Confusion Matrix:')\n","    print('-'*30)\n","    display_confusion_matrix(true_labels=true_labels, predicted_labels=predicted_labels, \n","                             classes=classes)\n","\n","def plot_model_roc_curve(clf, features, true_labels, label_encoder=None, class_names=None):\n","    \n","    ## Compute ROC curve and ROC area for each class\n","    fpr = dict()\n","    tpr = dict()\n","    roc_auc = dict()\n","    if hasattr(clf, 'classes_'):\n","        class_labels = clf.classes_\n","    elif label_encoder:\n","        class_labels = label_encoder.classes_\n","    elif class_names:\n","        class_labels = class_names\n","    else:\n","        raise ValueError('Unable to derive prediction classes, please specify class_names!')\n","    n_classes = len(class_labels)\n","    y_test = label_binarize(true_labels, classes=class_labels)\n","    if n_classes == 2:\n","        if hasattr(clf, 'predict_proba'):\n","            prob = clf.predict_proba(features)\n","            y_score = prob[:, prob.shape[1]-1] \n","        elif hasattr(clf, 'decision_function'):\n","            prob = clf.decision_function(features)\n","            y_score = prob[:, prob.shape[1]-1]\n","        else:\n","            raise AttributeError(\"Estimator doesn't have a probability or confidence scoring system!\")\n","        \n","        fpr, tpr, _ = roc_curve(y_test, y_score)      \n","        roc_auc = auc(fpr, tpr)\n","        plt.plot(fpr, tpr, label='ROC curve (area = {0:0.2f})'\n","                                 ''.format(roc_auc),\n","                 linewidth=2.5)\n","        \n","    elif n_classes > 2:\n","        if hasattr(clf, 'predict_proba'):\n","            y_score = clf.predict_proba(features)\n","        elif hasattr(clf, 'decision_function'):\n","            y_score = clf.decision_function(features)\n","        else:\n","            raise AttributeError(\"Estimator doesn't have a probability or confidence scoring system!\")\n","\n","        for i in range(n_classes):\n","            fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n","            roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","        ## Compute micro-average ROC curve and ROC area\n","        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n","        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","\n","        ## Compute macro-average ROC curve and ROC area\n","        # First aggregate all false positive rates\n","        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n","        # Then interpolate all ROC curves at this points\n","        mean_tpr = np.zeros_like(all_fpr)\n","        for i in range(n_classes):\n","            mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n","        # Finally average it and compute AUC\n","        mean_tpr /= n_classes\n","        fpr[\"macro\"] = all_fpr\n","        tpr[\"macro\"] = mean_tpr\n","        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n","\n","        ## Plot ROC curves\n","        plt.figure(figsize=(6, 4))\n","        plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n","                 label='micro-average ROC curve (area = {0:0.2f})'\n","                       ''.format(roc_auc[\"micro\"]), linewidth=3)\n","\n","        plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n","                 label='macro-average ROC curve (area = {0:0.2f})'\n","                       ''.format(roc_auc[\"macro\"]), linewidth=3)\n","\n","        for i, label in enumerate(class_labels):\n","            plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n","                                           ''.format(label, roc_auc[i]), \n","                     linewidth=2, linestyle=':')\n","    else:\n","        raise ValueError('Number of classes should be atleast 2 or more')\n","        \n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver Operating Characteristic (ROC) Curve')\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","def plot_model_decision_surface(clf, train_features, train_labels,\n","                                plot_step=0.02, cmap=plt.cm.RdYlBu,\n","                                markers=None, alphas=None, colors=None):\n","    \n","    if train_features.shape[1] != 2:\n","        raise ValueError(\"X_train should have exactly 2 columnns!\")\n","    \n","    x_min, x_max = train_features[:, 0].min() - plot_step, train_features[:, 0].max() + plot_step\n","    y_min, y_max = train_features[:, 1].min() - plot_step, train_features[:, 1].max() + plot_step\n","    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n","                         np.arange(y_min, y_max, plot_step))\n","\n","    clf_est = clone(clf)\n","    clf_est.fit(train_features,train_labels)\n","    if hasattr(clf_est, 'predict_proba'):\n","        Z = clf_est.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:,1]\n","    else:\n","        Z = clf_est.predict(np.c_[xx.ravel(), yy.ravel()])    \n","    Z = Z.reshape(xx.shape)\n","    cs = plt.contourf(xx, yy, Z, cmap=cmap)\n","    \n","    le = LabelEncoder()\n","    y_enc = le.fit_transform(train_labels)\n","    n_classes = len(le.classes_)\n","    plot_colors = ''.join(colors) if colors else [None] * n_classes\n","    label_names = le.classes_\n","    markers = markers if markers else [None] * n_classes\n","    alphas = alphas if alphas else [None] * n_classes\n","    for i, color in zip(range(n_classes), plot_colors):\n","        idx = np.where(y_enc == i)\n","        plt.scatter(train_features[idx, 0], train_features[idx, 1], c=color,\n","                    label=label_names[i], cmap=cmap, edgecolors='black', \n","                    marker=markers[i], alpha=alphas[i])\n","    plt.legend()\n","    plt.show()\n"],"metadata":{"id":"mtYsmo4VaLUG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Predicting Wine Types\n","\n","We will predict the wine type based on other features. To start with, we\n","will first select our necessary features and separate out the prediction class labels and prepare train and test\n","datasets. We use the prefix **wtp_** in our variables to easily identify them as needed, where **wtp** depicts wine\n","type prediction."],"metadata":{"id":"EshuYVJGaZKT"}},{"cell_type":"code","source":["wtp_features = wines.iloc[:,:-3]\n","wtp_feature_names = wtp_features.columns\n","wtp_class_labels = np.array(wines['wine_type'])\n","\n","# prepare train and test datasets\n","wtp_train_X, wtp_test_X, wtp_train_y, wtp_test_y = train_test_split(wtp_features, wtp_class_labels, \n","                                                                    test_size=0.3, random_state=42)\n","\n","print(Counter(wtp_train_y), Counter(wtp_test_y))\n","print('Features:', list(wtp_feature_names))"],"metadata":{"id":"aBMtfCKVaxYL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The numbers show us the wine samples for each class and we can also see the feature names which will\n","be used in our feature set."],"metadata":{"id":"P-vSMGE3a4l5"}},{"cell_type":"markdown","source":["##Feature Scaling\n","\n","We will be using a standard scaler in this\n","scenario."],"metadata":{"id":"v3dBYvDYbAj3"}},{"cell_type":"code","source":["# Define the scaler \n","wtp_ss = StandardScaler().fit(wtp_train_X)\n","\n","# Scale the train set\n","wtp_train_SX = wtp_ss.transform(wtp_train_X)\n","\n","# Scale the test set\n","wtp_test_SX = wtp_ss.transform(wtp_test_X)"],"metadata":{"id":"VPL5QwIpbO6k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Train a Model using Deep Learning (MLP)\n","\n","Let’s try\n","modeling the data using a fully connected deep neural network (DNN) with three hidden layers."],"metadata":{"id":"fdpnG3MxeBaa"}},{"cell_type":"markdown","source":["###Encodes wine type class labels"],"metadata":{"id":"0F2F15EMeZtl"}},{"cell_type":"code","source":["le = LabelEncoder()\n","le.fit(wtp_train_y)\n","# encode wine type labels\n","wtp_train_ey = le.transform(wtp_train_y)\n","wtp_test_ey = le.transform(wtp_test_y)"],"metadata":{"id":"Po2yYSbteiSt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Build & Compile DNN Model Architecture\n","Let’s build the architecture for our three-hidden layer DNN where each hidden layer has 16 units (the\n","input layer has 11 units for the 11 features) and the output layer has 1 unit to predict a 0 or 1, which maps\n","back to red or white wine. "],"metadata":{"id":"pP404btwesmB"}},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense\n","\n","# Build a sequential model of three-hidden layer DNN where each hidden layer has 16 units and 'relu' activation\n","# (the input layer has 11 units for the 11 features) and the output layer has 1 unit and 'sigmoid' activation\n","\n","# Your code goes here\n","\n","# Configures the model for training use 'Adam' as optimizer, 'binary_crossentropy' \n","# as loss funciton, and 'accuracy' as evaluation metrics\n","\n","# Your code goes here"],"metadata":{"id":"NphFfKseezIa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Train the Model\n","We use 10% of the training data for a validation set while training the model to see how it performs at\n","each epoch"],"metadata":{"id":"JJ9Eb6FifMif"}},{"cell_type":"code","source":["history = wtp_dnn_model.fit(wtp_train_SX, wtp_train_ey, epochs=10, batch_size=5, \n","                            shuffle=True, validation_split=0.1, verbose=1)"],"metadata":{"id":"W475mbZBfSRd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Predict on test data\n","Let’s now predict and evaluate our model on the actual test dataset."],"metadata":{"id":"fEz5eTj4fXzy"}},{"cell_type":"code","source":["wtp_dnn_ypred = wtp_dnn_model.predict(wtp_test_SX)\n","wtp_dnn_ypred = np.round(wtp_dnn_ypred).astype(int)\n","wtp_dnn_predictions = le.inverse_transform(np.ravel(wtp_dnn_ypred)) # make 1d array"],"metadata":{"id":"qzBzBEJ4fecM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Evaluate Model Performance"],"metadata":{"id":"6XTZUVNYg1cf"}},{"cell_type":"code","source":["display_model_performance_metrics(true_labels=wtp_test_y,predicted_labels=wtp_dnn_predictions, classes=['red', 'white'])"],"metadata":{"id":"jlBWpjQblV6H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We get an overall F1 Score and model accuracy of 99.5%, which is even\n","better than our previous model! This goes to prove you don’t always need big data but good quality data\n","and features even for Deep Learning models."],"metadata":{"id":"h4jhh7uUk_fg"}},{"cell_type":"code","source":["# Plot the loss and accurcy measures at each epoch\n","f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n","t = f.suptitle('Deep Neural Net Performance', fontsize=12)\n","f.subplots_adjust(top=0.85, wspace=0.3)\n","\n","epochs = list(range(1,11))\n","ax1.plot(epochs, history.history['accuracy'], label='Train Accuracy')\n","ax1.plot(epochs, history.history['val_accuracy'], label='Validation Accuracy')\n","ax1.set_xticks(epochs)\n","ax1.set_ylabel('Accuracy Value')\n","ax1.set_xlabel('Epoch')\n","ax1.set_title('Accuracy')\n","l1 = ax1.legend(loc=\"best\")\n","\n","ax2.plot(epochs, history.history['loss'], label='Train Loss')\n","ax2.plot(epochs, history.history['val_loss'], label='Validation Loss')\n","ax2.set_xticks(epochs)\n","ax2.set_ylabel('Loss Value')\n","ax2.set_xlabel('Epoch')\n","ax2.set_title('Loss')\n","l2 = ax2.legend(loc=\"best\")"],"metadata":{"id":"a9x8X2UThKoI"},"execution_count":null,"outputs":[]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python [conda root]","language":"python","name":"conda-root-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"Day_5_Exercise_1_Predicting_Wine_Types_Deep_Learing.ipynb","provenance":[{"file_id":"1F8M20pw0s9TeBooEae7N0TPi_QeAfVMu","timestamp":1647436564718},{"file_id":"13JWYttF88LiLbb8wi8FUS6RVUgnklc15","timestamp":1647436534392},{"file_id":"1BAwv-ZWceuHdPiMHaH5pIYTodebTOpPD","timestamp":1647425924042},{"file_id":"1BEYzOscw_o15MGFSkP82XY8ULEb0CBuY","timestamp":1647425788020},{"file_id":"https://github.com/dipanjanS/practical-machine-learning-with-python/blob/master/notebooks/Ch09_Analyzing_Wine_Types_and_Quality/Exploratory%20Data%20Analysis.ipynb","timestamp":1647368180157}],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}